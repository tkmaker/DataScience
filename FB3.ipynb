{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WIN8N0Eptkrc9wwGEAn2JE51xJkzdGjl",
      "authorship_tag": "ABX9TyPC2FMlDbfwRXQShd24iL/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkmaker/DataScience/blob/master/FB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SDp5apiiasf",
        "outputId": "1a8024ce-8f44-49fd-c83b-f792c731dc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 24 15:13:56 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWO1OkwgTC7",
        "outputId": "4292e878-9627-4eca-cd83-b84cfae2ea71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'feedback-ells'...\n",
            "warning: redirecting to https://tkmaker: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@github.com/rbiswasfc/feedback-ells.git/\n",
            "remote: Enumerating objects: 4810, done.\u001b[K\n",
            "remote: Counting objects: 100% (774/774), done.\u001b[K\n",
            "remote: Compressing objects: 100% (288/288), done.\u001b[K\n",
            "remote: Total 4810 (delta 529), reused 696 (delta 454), pack-reused 4036\u001b[K\n",
            "Receiving objects: 100% (4810/4810), 15.16 MiB | 8.35 MiB/s, done.\n",
            "Resolving deltas: 100% (3111/3111), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https:///tkmaker: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@github.com/rbiswasfc/feedback-ells.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/feedback-ells"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXDWGOpijIuV",
        "outputId": "99938109-d0f0-49db-e946-e6b1771da3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feedback-ells\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout tk_dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxTtkxhpjUnj",
        "outputId": "095032ba-0fa1-4f3b-b9b8-4e4e51d63750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'tk_dev' set up to track remote branch 'tk_dev' from 'origin'.\n",
            "Switched to a new branch 'tk_dev'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir /content/feedback-ells/datasets"
      ],
      "metadata": {
        "id": "Y2j36ADtoZXM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0bf8e2-25aa-4dd8-935f-d30572344a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/feedback-ells/datasets’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR4N4skihqCI",
        "outputId": "66f4b4e2-8612-4cb7-d2ad-7b631be1afea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[K     |████████████████████████████████| 166 kB 68.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 74.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 60.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 15.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 71.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 72.0 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 79.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=8bfb40b48a759f233a9052e0e09a059434486518af11d7b240e6c83522705a0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ghNy4t4IkIGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp /content/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "PBRMFYwmj_LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate transformers loguru datasets textstat readability pynvml bitsandbytes sentencepiece"
      ],
      "metadata": {
        "id": "n8RFwx-dpcp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7ddf76-b424-4575-b030-f64de9a1fa56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 35.6 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 52.6 MB/s \n",
            "\u001b[?25hCollecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
            "\u001b[K     |████████████████████████████████| 441 kB 75.2 MB/s \n",
            "\u001b[?25hCollecting textstat\n",
            "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 71.1 MB/s \n",
            "\u001b[?25hCollecting readability\n",
            "  Downloading readability-0.3.1.tar.gz (34 kB)\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.35.0-py3-none-any.whl (62.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 62.5 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from accelerate) (5.4.8)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->accelerate) (4.1.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 65.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 51.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.5 MB/s \n",
            "\u001b[?25hCollecting pyphen\n",
            "  Downloading pyphen-0.13.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 60.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Building wheels for collected packages: readability\n",
            "  Building wheel for readability (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for readability: filename=readability-0.3.1-py3-none-any.whl size=35475 sha256=e3f3b9eea6b9af4d0a8038942f4f2c6db48f41ebb37bac0cd25be501cb45409f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/8b/5a/ba40b81d8e91c7bc1d4226fa51d7b5943d147be122df515c19\n",
            "Successfully built readability\n",
            "Installing collected packages: urllib3, xxhash, tokenizers, responses, pyphen, multiprocess, huggingface-hub, transformers, textstat, sentencepiece, readability, pynvml, loguru, datasets, bitsandbytes, accelerate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed accelerate-0.13.2 bitsandbytes-0.35.0 datasets-2.6.1 huggingface-hub-0.10.1 loguru-0.6.0 multiprocess-0.70.13 pynvml-11.4.1 pyphen-0.13.0 readability-0.3.1 responses-0.18.0 sentencepiece-0.1.97 textstat-0.7.3 tokenizers-0.13.1 transformers-4.23.1 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/feedback-ells/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSRqz0T8xg4A",
        "outputId": "82b9172a-8d41-4cbc-f9c3-aa31b5fb5941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feedback-ells/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d trushk/fb3-ell-train-folds\n",
        "!kaggle competitions download -c feedback-prize-english-language-learning\n",
        "!kaggle datasets download -d trushk/fb3-en-pl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG4dbXxlyQZA",
        "outputId": "5b997969-7c94-4ccb-bb07-d0be251d367b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading fb3-ell-train-folds.zip to /content/feedback-ells/datasets\n",
            " 45% 5.00M/11.2M [00:00<00:00, 11.4MB/s]\n",
            "100% 11.2M/11.2M [00:00<00:00, 22.3MB/s]\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading feedback-prize-english-language-learning.zip to /content/feedback-ells/datasets\n",
            "  0% 0.00/2.80M [00:00<?, ?B/s]\n",
            "100% 2.80M/2.80M [00:00<00:00, 212MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZe0sUAKvFNR",
        "outputId": "1b758731-4be1-4528-a2dc-e59a1e59bfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading fb3-en-pl.zip to /content/feedback-ells/datasets\n",
            " 49% 9.00M/18.5M [00:00<00:00, 12.5MB/s]\n",
            "100% 18.5M/18.5M [00:00<00:00, 24.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip fb3-ell-train-folds.zip -d processed\n",
        "!unzip feedback-prize-english-language-learning.zip -d feedback-prize-english-language-learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wehMZc6hxiaD",
        "outputId": "92100013-1101-477d-8ff5-2527415b57f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  fb3-ell-train-folds.zip\n",
            "  inflating: processed/train_10folds.csv  \n",
            "  inflating: processed/train_4folds.csv  \n",
            "  inflating: processed/train_5folds.csv  \n",
            "  inflating: processed/train_8folds.csv  \n",
            "Archive:  feedback-prize-english-language-learning.zip\n",
            "  inflating: feedback-prize-english-language-learning/sample_submission.csv  \n",
            "  inflating: feedback-prize-english-language-learning/test.csv  \n",
            "  inflating: feedback-prize-english-language-learning/train.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/feedback-ells/datasets/processed/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAc60gjFwUlb",
        "outputId": "83b47391-4e07-41f8-ddea-cb5eb2a3d00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feedback-ells/datasets/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/feedback-ells/datasets/fb3-en-pl.zip -d pl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1NZAtkpwdPe",
        "outputId": "d25afbe0-d01e-424c-aeef-91e77b807f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/feedback-ells/datasets/fb3-en-pl.zip\n",
            "  inflating: pl/ens001/ens001_fold0.csv  \n",
            "  inflating: pl/ens001/ens001_fold1.csv  \n",
            "  inflating: pl/ens001/ens001_fold2.csv  \n",
            "  inflating: pl/ens001/ens001_fold3.csv  \n",
            "  inflating: pl/pl_data.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/feedback-ells/code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm7EaghHkIrq",
        "outputId": "873fe2c9-ecf7-4991-8acf-ba6ade49b387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/feedback-ells/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga2c6y05qOJp",
        "outputId": "a82dd84d-dbf2-4541-e56a-f955f5a4fe59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python train_fts.py --config configs/exp_config_dbase.json --use_wandb --fold 0"
      ],
      "metadata": {
        "id": "WdFaiWJWkfSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be0f1340-2d35-49e6-934d-51df1d09918a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "Moving 0 files to the new cache system\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "/usr/local/lib/python3.7/dist-packages/bitsandbytes/cuda_setup/paths.py:106: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  f'{candidate_env_vars[\"LD_LIBRARY_PATH\"]} did not contain '\n",
            "/usr/local/lib/python3.7/dist-packages/bitsandbytes/cuda_setup/paths.py:28: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('{\"kernelManagerProxyPort\"'), PosixPath('\"172.28.0.3\",\"jupyterArgs\"'), PosixPath('\"/usr/local/bin/dap_multiplexer\",\"enableLsp\"'), PosixPath('true}'), PosixPath('6000,\"kernelManagerProxyHost\"'), PosixPath('[\"--ip=172.28.0.2\"],\"debugAdapterMultiplexerPath\"')}\n",
            "  \"WARNING: The following directories listed in your path were found to \"\n",
            "/usr/local/lib/python3.7/dist-packages/bitsandbytes/cuda_setup/paths.py:28: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  \"WARNING: The following directories listed in your path were found to \"\n",
            "/usr/local/lib/python3.7/dist-packages/bitsandbytes/cuda_setup/paths.py:28: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  \"WARNING: The following directories listed in your path were found to \"\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 112\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.7/dist-packages/bitsandbytes/libbitsandbytes_cuda112.so...\n",
            "================================================================================\n",
            "setting seed: 636\n",
            "train folds: [1, 2, 3, 999]\n",
            "valid folds: [0]\n",
            "================================================================================\n",
            "                 text_id  ...                                          full_text\n",
            "0  000E6DE9E817_bk5v8082  ...  Dear: Principal\\n\\nI am arguing against the po...\n",
            "1           0016926B079C  ...  I think that students would benefit from learn...\n",
            "2  0016926B079C_2vj000nu  ...  My opinion is that you should have online clas...\n",
            "3  0016926B079C_7nxinzwa  ...  Students would benefit from being able to atte...\n",
            "4  0016926B079C_bwv1k2wa  ...  I think they would benefit from taking online ...\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "Essay shape before train removal: (19911, 9)\n",
            "Essay shape after train removal: (16978, 9)\n",
            "Essay shape before valid removal: (16978, 9)\n",
            "Essay shape after valid removal: (16000, 9)\n",
            "---------------\n",
            "Augmented 4000 essays\n",
            "---------------\n",
            "creating the datasets and data loaders...\n",
            "shape of train data: (6933, 11)\n",
            "shape of valid data: (978, 11)\n",
            "using auto tokenizer\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "================================================================================\n",
            "tokenizer len: 128001\n",
            "================================================================================\n",
            "tokenizer len: 128001\n",
            "================================================================================\n",
            "processing essay text and inserting new tokens at span boundaries\n",
            "================================================================================\n",
            "        text_id  ... polysyllabcount\n",
            "0  0016926B079C  ...            11.0\n",
            "2  00299B378633  ...            23.0\n",
            "3  003885A45F42  ...            29.0\n",
            "4  0049B1DF5CCC  ...             8.0\n",
            "5  004AC288D833  ...            34.0\n",
            "\n",
            "[5 rows x 22 columns]\n",
            "100% 6933/6933 [00:10<00:00, 654.90ex/s]\n",
            " 86% 6/7 [00:03<00:00,  1.54ba/s]\n",
            " 86% 6/7 [00:04<00:00,  1.40ba/s]\n",
            " 86% 6/7 [00:03<00:00,  1.52ba/s]\n",
            "using auto tokenizer\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "================================================================================\n",
            "tokenizer len: 128001\n",
            "================================================================================\n",
            "tokenizer len: 128001\n",
            "================================================================================\n",
            "processing essay text and inserting new tokens at span boundaries\n",
            "================================================================================\n",
            "         text_id  ... polysyllabcount\n",
            "1   0022683E9EA5  ...            33.0\n",
            "6   005661280443  ...             9.0\n",
            "11  00BCADB373EF  ...            44.0\n",
            "12  00D281524375  ...            13.0\n",
            "13  00ED2563D0B1  ...            72.0\n",
            "\n",
            "[5 rows x 22 columns]\n",
            "100% 978/978 [00:01<00:00, 603.67ex/s]\n",
            "  0% 0/1 [00:00<?, ?ba/s]\n",
            "  0% 0/1 [00:00<?, ?ba/s]\n",
            "  0% 0/1 [00:00<?, ?ba/s]\n",
            "data preparation done...\n",
            "================================================================================\n",
            "creating the model, optimizer and scheduler...\n",
            "Downloading: 100% 371M/371M [00:05<00:00, 71.6MB/s]\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight']\n",
            "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "FeedbackModel(\n",
            "  (aux_loss_fn): BCELoss()\n",
            "  (base_model): DebertaV2Model(\n",
            "    (embeddings): DebertaV2Embeddings(\n",
            "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "      (dropout): StableDropout()\n",
            "    )\n",
            "    (encoder): DebertaV2Encoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (1): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (2): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (3): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (4): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (5): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (6): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (7): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (8): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (9): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (10): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "        (11): DebertaV2Layer(\n",
            "          (attention): DebertaV2Attention(\n",
            "            (self): DisentangledSelfAttention(\n",
            "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (pos_dropout): StableDropout()\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "            (output): DebertaV2SelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "              (dropout): StableDropout()\n",
            "            )\n",
            "          )\n",
            "          (intermediate): DebertaV2Intermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): DebertaV2Output(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "            (dropout): StableDropout()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (rel_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (head): Linear(in_features=3072, out_features=6, bias=True)\n",
            ")\n",
            "# updates per epoch: 434\n",
            "# training steps: 2604\n",
            "# warmup steps: 130\n",
            "model preparation done...\n",
            "current GPU utilization...\n",
            "GPU memory occupied: 2290 MB.\n",
            "================================================================================\n",
            "initializing wandb run...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtkmaker\u001b[0m (\u001b[33mkaggle-clrp\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/feedback-ells/code/wandb/run-20221024_161757-1pvamse5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp201a-debv3-b-mean-fc-enpl-fold0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/kaggle-clrp/feedback-prize-ell-tk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/kaggle-clrp/feedback-prize-ell-tk/runs/1pvamse5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "  0% 0/434 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   434/  434. LR: 19.2641. TL: 0.5340. : 100% 434/434 [20:36<00:00,  2.30s/it]\n",
            "\n",
            "GPU Utilization before evaluation...\n",
            "\n",
            "\n",
            "GPU memory occupied: 7244 MB.\n",
            "valid score = 0.4556363523006439 scores= [0.49371016, 0.45734018, 0.41409066, 0.44979143, 0.46985218, 0.4490334]\n",
            "GPU Utilization after evaluation...\n",
            "GPU memory occupied: 4770 MB.\n",
            "================================================================================\n",
            "STEP:   434/  434. LR: 19.2641. TL: 0.5340. : 100% 434/434 [21:22<00:00,  2.95s/it]\n",
            "  0% 0/434 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   434/  434. LR: 15.9209. TL: 0.2899. : 100% 434/434 [20:38<00:00,  2.30s/it]\n",
            "\n",
            "GPU Utilization before evaluation...\n",
            "\n",
            "\n",
            "GPU memory occupied: 8436 MB.\n",
            "valid score = 0.4485992193222046 scores= [0.4847471, 0.4515007, 0.40634647, 0.44508743, 0.46368808, 0.44022566]\n",
            "AWP is triggered...\n",
            "GPU Utilization after evaluation...\n",
            "GPU memory occupied: 4710 MB.\n",
            "================================================================================\n",
            "STEP:   434/  434. LR: 15.9209. TL: 0.2899. : 100% 434/434 [21:25<00:00,  2.96s/it]\n",
            "  0% 0/434 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   434/  434. LR: 10.8245. TL: 0.2708. : 100% 434/434 [41:05<00:00,  4.56s/it]\n",
            "\n",
            "GPU Utilization before evaluation...\n",
            "\n",
            "\n",
            "GPU memory occupied: 9970 MB.\n",
            "valid score = 0.4522306025028229 scores= [0.48742187, 0.45350608, 0.41235772, 0.44865215, 0.46799937, 0.44344628]\n",
            "patience reached 1/25\n",
            "AWP is triggered...\n",
            "GPU Utilization after evaluation...\n",
            "GPU memory occupied: 5614 MB.\n",
            "================================================================================\n",
            "STEP:   434/  434. LR: 10.8245. TL: 0.2708. : 100% 434/434 [41:45<00:00,  5.77s/it]\n",
            "  0% 0/434 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   434/  434. LR: 5.4839. TL: 0.2516. : 100% 434/434 [41:03<00:00,  4.57s/it]\n",
            "\n",
            "GPU Utilization before evaluation...\n",
            "\n",
            "\n",
            "GPU memory occupied: 9978 MB.\n",
            "valid score = 0.450300008058548 scores= [0.48362583, 0.45221522, 0.40877828, 0.44692788, 0.46792176, 0.44233108]\n",
            "patience reached 2/25\n",
            "AWP is triggered...\n",
            "GPU Utilization after evaluation...\n",
            "GPU memory occupied: 5854 MB.\n",
            "================================================================================\n",
            "STEP:   434/  434. LR: 5.4839. TL: 0.2516. : 100% 434/434 [41:43<00:00,  5.77s/it]\n",
            "  0% 0/434 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   434/  434. LR: 1.4806. TL: 0.2364. : 100% 434/434 [41:03<00:00,  4.49s/it]\n",
            "\n",
            "GPU Utilization before evaluation...\n",
            "\n",
            "\n",
            "GPU memory occupied: 10026 MB.\n",
            "valid score = 0.4515552818775177 scores= [0.48420987, 0.45360366, 0.409903, 0.44702557, 0.47026736, 0.44432238]\n",
            "patience reached 3/25\n",
            "AWP is triggered...\n",
            "GPU Utilization after evaluation...\n",
            "GPU memory occupied: 5918 MB.\n",
            "================================================================================\n",
            "STEP:   434/  434. LR: 1.4806. TL: 0.2364. : 100% 434/434 [41:43<00:00,  5.77s/it]\n",
            "  0% 0/434 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scale, dtype=query_layer.dtype\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n",
            "STEP:   257/  434. LR: 0.2515. TL: 0.2292. :  59% 257/434 [24:21<16:45,  5.68s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CUDA_VISIBLE_DEVICES=0 python train_pet.py --config-name debv3_base_prompt use_wandb=true fold=0 outputs.model_dir=/content/drive/MyDrive/feedback3/e20  wandb.run_name=e206-pet-debv3l-smooth \"ensemble_pl.pl_paths=[ ../datasets/processed/pl/ens001_fold0.csv ]\""
      ],
      "metadata": {
        "id": "gztq52btt2yb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}